{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 0: Install dependencies\n",
        "\n"
      ],
      "metadata": {
        "id": "K3yWWtQ8cC4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU google-generativeai==0.8.5 google-ai-generativelanguage==0.6.15 \\\n",
        "langgraph langchain langchain-google-genai openai"
      ],
      "metadata": {
        "id": "Y57PNO0kBhU4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 1: Imports and secure API key input"
      ],
      "metadata": {
        "id": "XvoFPl11cFhj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass #for securing and enables for getting api as password. anything which is passed inside getpass will become a password\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage"
      ],
      "metadata": {
        "id": "KC51AyRkC5CP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Secure Gemini API Key input"
      ],
      "metadata": {
        "id": "W28u20SxcIiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['GOOGLE_API_KEY']=getpass.getpass('Please enter your Gemini API key: ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vx5qfOyGMdE",
        "outputId": "6691cc44-5229-4e01-bb9e-ca380d755933"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your Gemini API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 2: Initialize Gemini 1.5 Flash"
      ],
      "metadata": {
        "id": "eusINPuVcLXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm=ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",temperature=0.2)\n",
        "#temperature controls the randomness, higher temp it will become creative\n",
        "#if temperature is low, then ai will give the same output"
      ],
      "metadata": {
        "id": "Q2mMPtufGz28"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 3: Node to ask user for symptom"
      ],
      "metadata": {
        "id": "o07zbkLWcOVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_symptom(state:dict)->dict:\n",
        "  symptom=input(\"Welcome to XYZ Hospital, Please enter your symptom: \")\n",
        "  state[\"symptom\"]=symptom\n",
        "  return state"
      ],
      "metadata": {
        "id": "V7C9fX63I_Pq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 4: Node to classify the symptom"
      ],
      "metadata": {
        "id": "0KIzyYPVcRVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "def classify_symptom(state: dict) -> dict:\n",
        "    prompt = (\n",
        "        \"You are a helpful medical agent. Classify the symptom below into one of these categories:\\n\"\n",
        "        \"- General\\n- Emergency\\n- Mental Health\\n\\n\"\n",
        "        f\"Symptom: {state['symptom']}\\n\\n\"\n",
        "        \"Respond only with one word: General, Emergency, or Mental Health.\\n\"\n",
        "        \"Example: input: I have fever → Output: General\"\n",
        "    )\n",
        "\n",
        "    response = llm.invoke([HumanMessage(content=prompt)])\n",
        "    category = response.content.strip()\n",
        "\n",
        "    print(f\"LLM Classifies the symptom as: {category}\")\n",
        "    state[\"category\"] = category\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "jm2nF7k5J0Ez"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 5: Router logic to route to the correct node\n"
      ],
      "metadata": {
        "id": "kESmxbnicWpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def symptom_router(state: dict) -> str:\n",
        "    cat = state[\"category\"].lower().replace(\" \", \"-\")\n",
        "\n",
        "    if \"general\" in cat:\n",
        "        return \"general\"\n",
        "    elif \"emergency\" in cat:\n",
        "        return \"emergency\"\n",
        "    elif \"mental-health\" in cat:\n",
        "        return \"mental-health\"\n",
        "    else:\n",
        "        return \"general\"  # Default fallback route\n"
      ],
      "metadata": {
        "id": "v5aBJ0nuND8W"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 6: Category-specific response nodes\n"
      ],
      "metadata": {
        "id": "cZuR4VGscake"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def general_node(state: dict) -> dict:\n",
        "    state[\"answer\"] = (\n",
        "        f\"'{state['symptom']}': Seems like a general issue. \"\n",
        "        \"Directing you to the General Ward for consultation.\"\n",
        "    )\n",
        "    return state\n",
        "\n",
        "def emergency_node(state: dict) -> dict:\n",
        "    state[\"answer\"] = (\n",
        "        f\"'{state['symptom']}': This is classified as a **Medical Emergency**. \"\n",
        "        \"Seeking immediate assistance.\"\n",
        "    )\n",
        "    return state\n",
        "\n",
        "def mental_health_node(state: dict) -> dict:\n",
        "    state[\"answer\"] = (\n",
        "        f\"'{state['symptom']}': This may be related to **mental health**. \"\n",
        "        \"Please talk to our mental health consultant.\"\n",
        "    )\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "wbW72VAvOdQ3"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 7: Build LangGraph\n"
      ],
      "metadata": {
        "id": "I1ek0SwzcehS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    symptom: str\n",
        "    category: str\n",
        "    answer: str\n",
        "\n",
        "builder = StateGraph(GraphState)\n",
        "\n",
        "# Define nodes\n",
        "builder.set_entry_point(\"get_symptom\")\n",
        "builder.add_node(\"get_symptom\", get_symptom)\n",
        "builder.add_node(\"classify\", classify_symptom)\n",
        "builder.add_node(\"general\", general_node)\n",
        "builder.add_node(\"emergency\", emergency_node)\n",
        "builder.add_node(\"mental-health\", mental_health_node)\n",
        "\n",
        "# Define edges\n",
        "builder.add_edge(\"get_symptom\", \"classify\")\n",
        "builder.add_conditional_edges(\"classify\", symptom_router, {\n",
        "    \"general\": \"general\",\n",
        "    \"emergency\": \"emergency\",\n",
        "    \"mental-health\": \"mental-health\"\n",
        "})\n",
        "builder.add_edge(\"general\", END)\n",
        "builder.add_edge(\"emergency\", END)\n",
        "builder.add_edge(\"mental-health\", END)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0GTVGbfP9D5",
        "outputId": "0c7a40aa-cd4d-482b-dada-b168c4bf0629"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7d9b5eddd010>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 8: Compile and invoke the graph\n"
      ],
      "metadata": {
        "id": "GbAgCeZYci5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile & show graph\n",
        "graph = builder.compile()\n",
        "mermaid = graph.get_graph()\n",
        "print(\"Mermaid Graph:\")\n",
        "print(mermaid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfNxn1yxURVR",
        "outputId": "b9655b44-55a7-4f4f-9209-81a7cc2e5b37"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mermaid Graph:\n",
            "Graph(nodes={'__start__': Node(id='__start__', name='__start__', data=RunnableCallable(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None), 'get_symptom': Node(id='get_symptom', name='get_symptom', data=get_symptom(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None), 'classify': Node(id='classify', name='classify', data=classify(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None), 'general': Node(id='general', name='general', data=general(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None), 'emergency': Node(id='emergency', name='emergency', data=emergency(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None), 'mental-health': Node(id='mental-health', name='mental-health', data=mental-health(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None), '__end__': Node(id='__end__', name='__end__', data=None, metadata=None)}, edges=[Edge(source='__start__', target='get_symptom', data=None, conditional=False), Edge(source='classify', target='emergency', data=None, conditional=True), Edge(source='classify', target='general', data=None, conditional=True), Edge(source='classify', target='mental-health', data=None, conditional=True), Edge(source='get_symptom', target='classify', data=None, conditional=False), Edge(source='emergency', target='__end__', data=None, conditional=False), Edge(source='general', target='__end__', data=None, conditional=False), Edge(source='mental-health', target='__end__', data=None, conditional=False)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_state = graph.invoke({})\n",
        "print(\"Final output:\")\n",
        "print(final_state[\"answer\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHCdpldLSKjC",
        "outputId": "d168b573-093b-4506-a068-680f895f78f7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to XYZ Hospital, Please enter your symptom: cough and cold\n",
            "LLM Classifies the symptom as: General\n",
            "Final output:\n",
            "'cough and cold': Seems like a general issue. Directing you to the General Ward for consultation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PuwXHlbxSZNB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}